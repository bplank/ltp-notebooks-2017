{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Convolutional Neural Networks (CNNs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Computer Vision (CV): image classification, caption generation, photo tagging, self-driving cars\n",
    "* Convolution-and-pooling architectures (LeCun & Bengio, 1995) evolved in the neural\n",
    "networks vision community"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* invariance in data:\n",
    "  * image of kitten in different positions in image \n",
    "  * want to find object regardless of its position in the image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolutional neural networks (CNNs or convnets) are a  specialized kind of neural network **for processing data that has a known, grid-like topology** [[1](http://www.deeplearningbook.org/contents/convnets.html)]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Image data**: can be thought of a 2-dimensional (grid) \n",
    "* **Text data**: 1-d (sequence) / time-series data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The name **convolution** comes from the fact that this model uses a mathematical operation called *convolution*. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## CNNs (or 'convnets')\n",
    "\n",
    "* are Neural Networks that works on variable length inputs\n",
    "* the name **convolution** comes from the fact that this model uses a mathematical operation called *convolution*. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* the two basic operations of a CNN are **convolution** and **pooling** \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### What are convolutions?\n",
    "\n",
    "* \"identifying indicative local predictors\" (Goldberg, 2015)\n",
    "* a grid goes over the input \n",
    "\n",
    "#### Example of a 2d convolution:\n",
    "\n",
    "An image is a 2d input, the following illustrates a convolution over this 2d input:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"http://neuralnetworksanddeeplearning.com/images/tikz44.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src=\"http://neuralnetworksanddeeplearning.com/images/tikz45.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Here is an animation (src: Convolution with 3Ã—3 Filter). Source: http://deeplearning.stanford.edu/wiki/index.php/Feature_extraction_using_convolution)\n",
    "<img src=\"http://deeplearning.stanford.edu/wiki/images/6/6c/Convolution_schematic.gif\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Pooling\n",
    "\n",
    "Max pooling in CNN. Source: http://cs231n.github.io/convolutional-networks/#pool\n",
    "<img src=\"http://d3kbpzbmcynnmx.cloudfront.net/wp-content/uploads/2015/11/Screen-Shot-2015-11-05-at-2.18.38-PM.png\" width=600>\n",
    "\n",
    "stride: 2 pixels (jumps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What are convnets?\n",
    "\n",
    "* several layers of convolutions (with activation functions) and pooling\n",
    "\n",
    "<img src=\"http://d3kbpzbmcynnmx.cloudfront.net/wp-content/uploads/2015/11/Screen-Shot-2015-11-07-at-7.26.20-AM.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Convolutions for text\n",
    "\n",
    "* CNNs were introduced in NLP by Collobert et al. (2011) and later by Kim (2014) and Kalchbrenner et al. (2014)\n",
    "* the intention is to let the network focus on the most important \"features\" in the sentence, regardless of their location\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In NLP we are mainly interested in **1D** (sequence) convolutions (Goldberg, 2015):\n",
    "    \n",
    "* a k-word sliding window is input for a function (**filter**) that transforms the window of k words into a d dimensional vector (where each dimension is called a **channel**)\n",
    "* then, a pooling operation combines vectors from different windows into a d-dim vector by taking the max or average value observed in each of the channels (max pooling/average pooling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src=\"pics/cnn-goldberg.png\">\n",
    "Illustration from Goldberg (2015) chapter 9. The resulting vector is a representation for the entire sentence in which each dimension represents the most salient features for some prediction task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We can also do different convolutions on different parts of the sentence/document (see section 9.2, Goldberg)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Kim (2014)\n",
    "\n",
    "* apply several convoluational layers in parallel\n",
    "<img src=\"pics/kim2014.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "### in Keras (from keras examples):\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Flatten\n",
    "from keras.layers.core import Lambda, Dropout, Dense, Activation\n",
    "from keras.layers.convolutional import Convolution1D\n",
    "from keras import backend as K\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(output_dim=128, input_dim=10000, input_length=5))\n",
    "\n",
    "nb_filter = 250\n",
    "filter_length = 3\n",
    "hidden_dims = 250\n",
    "\n",
    "# we add a Convolution1D, which will learn nb_filter\n",
    "# word group filters of size filter_length:\n",
    "model.add(Convolution1D(nb_filter=nb_filter,  # Number of convolution kernels to use (dimensionality of the output).\n",
    "                            filter_length=filter_length, #  The extension (spatial or temporal) of each filter.\n",
    "                            border_mode='valid',  #valid: don't go off edge; same: use padding before applying filter\n",
    "                            activation='relu',\n",
    "                            subsample_length=1))\n",
    "\n",
    "\n",
    "# we use max over time pooling by defining a python function to use\n",
    "# in a Lambda layer\n",
    "def max_1d(X):\n",
    "    return K.max(X, axis=1)\n",
    "model.add(Lambda(max_1d, output_shape=(nb_filter,)))\n",
    "\n",
    "# We add a vanilla hidden layer:\n",
    "model.add(Dense(hidden_dims))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Activation('relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## References\n",
    "\n",
    "* [Goldberg's primer chapter 9](arxiv.org/abs/1510.00726)\n",
    "* [WildML: CNNs for NLP](http://www.wildml.com/2015/11/understanding-convolutional-neural-networks-for-nlp/#more-348)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
